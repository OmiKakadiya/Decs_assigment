flask.c file included civetweb.h header file.

To execute flask.c
just simply do make 
and then run ./flask <portno> <threads>

Experiment Report

1. Aim/Purpose of the Experiment
The objective of this experiment is to analyze the performance of the server under varying 
levels of concurrent requests and thread configurations. 
This test is carried out for 3 different functions:-

1./hello
2./square
3./arithmetic/prime

2. Setup and Execution Details Environment:

Server:Server is built using civetwebhttp.h library handling mulitple endpoints 
Load Generator: Apache Bench (ab) for consistent and repeatable results.
Thread Configurations Tested: 250, 500, and 1000 Threads
Concurrent Requests: 10, 20, 30, 40, 50, 60
Metrics Collected: Requests per Second (Throughput)


3. Hypothesis/Expectation
Initial Hypothesis: Increasing the number of threads should improve throughput, 
especially under higher concurrency levels, up to a certain limit. However, at 
very high thread counts, we might encounter diminishing returns due to CPU and 
memory limitations or overhead from thread management.
Expectation by Concurrent Requests: We expect that as the number of concurrent 
requests increases, the server will handle more requests per second up to a 
point where the throughput may stabilize or potentially decrease due to resource contention.

4. Observations from the Data/Plots
Throughput Variability Across Threads:
As the number of threads increases from 250 to 1000, the throughput shows a general upward trend in each dataset , where 1000 threads consistently outperform both 250 and 500 threads

Thread Saturation Effects:
In the 1000-thread configuration, there are signs of throughput saturation around the 60k requests mark, with no significant throughput gains or minor declines observed in the highest request range across all three datasets.

Performance Consistency:
For 250 threads, throughput appears to be more inconsistent and has relatively lower values across requests ,indicating limitations in handling higher requests with fewer threads.
500 and 1000 threads demonstrate relatively stable throughput, with the 1000-thread configuration showing minimal fluctuations and the highest performance overall.


5. Explanation of Behavior and Inferences

As thread count increases, each thread is able to handle its own share of incoming requests, improving overall throughput , especially when comparing 250 threads (with lower throughput and higher variance) against 500 and 1000 threads.
The 500-thread configuration often achieves a good balance, reaching relatively high throughput while maintaining stability. This could imply that while 1000 threads maximize throughput, they may introduce higher system overhead, making 500 threads a potentially optimal choice in terms of efficiency and resource utilization.